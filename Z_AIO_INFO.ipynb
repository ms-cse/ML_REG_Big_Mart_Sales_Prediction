{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a5fd1b-c27c-4216-9655-4df11a862d2e",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION DETAILS\n",
    "### TYPE - ML Regression\n",
    "### PROJECT - \"Big Mart Sales\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ff8af-1801-4407-9958-96451b662180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A. DATA ASSESSMENT PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaee14e-51ba-4b23-af43-1f98a2e27d10",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. DATASET SUMMARY\n",
    "### - It is a 'Big Mart Sales' dataset that provides the information about various features to predict the sales of products at different stores.\n",
    "### - Train dataset has 8523 observations and 12 features.\n",
    "### - Test dataset has 5681 observations and 11 features.\n",
    "\n",
    "### - Total 'float' type features are 4, 'integer' type features are 1, and 'object' type features are 7.\n",
    "#### - float type : 'Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales'.\n",
    "#### - int type : 'Outlet_Establishment_Year'.\n",
    "#### - object type : 'Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'.\n",
    "\n",
    "### - For machine learning applications 'Item_Outlet_Sales' feature is the target variable (dependent) and the other 11 features are input (independent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58787436-4adf-4546-b8c1-4589b63f4968",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. FEATURE DESCRIPTIONS\n",
    "### Table - 'bms_train' using 'bms_train.csv'\n",
    "### - 'Item_Identifier' feature {object type, independent feature} - ***Unique identifier number assigned to each item.***\n",
    "### - 'Item_Weight' feature {float type, independent feature} - ***Item weight in gms.***\n",
    "### - 'Item_Fat_Content' feature {object type, independent feature} - ***Item fat content.***\n",
    "### - 'Item_Visibility' feature {float type, independent feature} - ***Percentage of total display area of all items in a store allocated to the particular items. Placement value of each item: (0 - 'Far & Behind') and (1 - 'Near & Front')***\n",
    "### - 'Item_Type' feature {object type, independent feature} - ***Type of food category item belongs to.***\n",
    "### - 'Item_MRP' feature {float type, independent feature} - ***Max. Retail Price of the item in the outlet.***\n",
    "### - 'Outlet_Identifier' feature {object type, independent feature} - ***Unique outlet identifier.***\n",
    "### - 'Outlet_Establishment_Year' feature {int type, independent feature} - ***Year of outlet establishment.***\n",
    "### - 'Outlet_Size' feature {object type, independent feature} - ***Size of the outlet.***\n",
    "### - 'Outlet_Location_Type' feature {object type, independent feature} - ***Tier of city in which outlet is located.***\n",
    "### - 'Outlet_Type' feature {object type, independent feature} - ***Type of outlet.***\n",
    "### - 'Item_Outlet_Sales' feature {float type, dependent feature} - ***Sales of the item from the outlet.***\n",
    "#### -- This feature is the target variable for Machine Learning Based Regression Type Problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b915482-cda7-4443-9782-376e30436550",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3. DATA ISSUES\n",
    "### Table - bms_train\n",
    "#### 1. * Dirty Data (Low quality)\n",
    "##### A. Completeness\n",
    "##### - Missing Values: Item_Weight=1463, Outlet_Size=2410\n",
    "##### B. Validity\n",
    "##### - No duplicate observations\n",
    "##### C. Accuracy\n",
    "##### - No inaccuracy issue\n",
    "##### D. Consistency\n",
    "##### - \"Item_Fat_Content\" feature values to be marked as 'Non Edible' where the context is 'Non Consumables'.\n",
    "##### - \"Item_Fat_Content\" feature values 'LF','low fat' must be mapped to 'Low Fat' and 'reg' must be mapped to 'Regular'.\n",
    "##### - \"Item_Type\" feature values to be marked as 'DR_Dairy' and 'FD_Dairy', where the context is 'Drinks' and 'Foods' respectively.\n",
    "\n",
    "#### 2. * Messy Data (Untidy / Structural)\n",
    "##### - No messy data issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdcf822-d85d-4396-a990-9926c6968c8f",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# B. PRE-PROCESSING / DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043b210-f109-42ce-8290-33424b6a7224",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing Level - I.\n",
    "\n",
    "### - Nothing to pre-process\n",
    "### - Splitting the dataframe into Train, Validation, and Test datasets using 'bms_train.csv', ***successful***.\n",
    "\n",
    "### - Saving the split data into CSV and PKL files, ***successful***.\n",
    "#### . Train ('bms_train_init.csv','bms_train_init.pkl')\n",
    "#### . Validation ('bms_valid_init.csv','bms_valid_init.pkl')\n",
    "#### . Test ('bms_test_init.csv','bms_test_init.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c15413-6471-42e2-94ff-544a9ecba861",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing Level - II. (Train, Validation, and Test datasets)\n",
    "\n",
    "### - Creating a high level item category as 'Item_Category' using 'Item_Identifier' feature by selecting first two letters of the feature values. (FD, DR, NC) ---> (Foods, Drinks, Non Consumables), ***successful***.\n",
    "### - Imputing missing values for the Features, ***successful***.\n",
    "#### -- 'Item_Weight': using mapping of 'Item_Identifier' and 'Item_Weight' wherever available.\n",
    "##### --- if new item, then using the median value wieght of 'Item_Category' (derived feature).\n",
    "#### -- 'Outlet_Size': calculating mode value using 'Outlet_Type' \n",
    "### - Marking the 'Item_Fat_Content' value as 'Non Edible', where 'Item_Category' is 'Non Consumables', ***successful***. \n",
    "### - Remapping the feature values of \"Item_Fat_Content\" ('LF','low fat') to 'Low Fat', 'reg' to 'Regular', ***successful***.\n",
    "### - Marking the 'Item_Type' as 'Dairy Drinks' and 'Dairy Foods' where the 'Item_Category' is 'Drinks' and 'Foods' respectively, ***successful***.\n",
    "### - Creating new feature 'Outlet_Age' from 'Outlet_Establishment_Year' by expression = 2013-year, ***successful***.\n",
    "### - Correcting 'Item_Visibility' if 0, replace with mean, ***successful***.\n",
    "\n",
    "### - Saving the pre-processed data into CSV and PKL files, ***successful***.\n",
    "#### . Train ('bms_train_pp.csv','bms_train_pp.pkl')\n",
    "#### . Validation ('bms_valid_pp.csv','bms_valid_pp.pkl')\n",
    "#### . Test ('bms_test_pp.csv','bms_test_pp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153b598-605b-4190-84c5-4c0c02eb806a",
   "metadata": {},
   "source": [
    "# C. EDA CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d3280-37f6-47ed-ae5e-1adeda49adf3",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## a. Uni-Variate EDA conclusions\n",
    "\n",
    "### . Numerical Features\n",
    "#### - There are no missing values in any of the features.\n",
    "#### - Some features have highly skewed distribution i.e., features are not Normally Distributed.\n",
    "#### - Outliers vary in the range of (0-2.18) % for the features.\n",
    "\n",
    "### . Categorical Features \n",
    "#### - 'Item_Identifier' feature uniquely identifies each product and has lot of categories, can be dropped for model buidling.\n",
    "#### - 'Outlet_Identifier' feature uniquely indentifies each store, can be dropped for model building.\n",
    "#### - 'Item_Type' has lot of unique categorical values, needs to be handled.\n",
    "#### - 'Outlet_Establishment_Year' feature is used to create new feature 'Outlet_Age'. So, can be dropped for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682c50f-e781-45d4-b9a5-1004b8e75810",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## b. Bi Variate EDA conclusions\n",
    "\n",
    "### . Numerical-Numerical ('Item_Outlet_Sales' vs others)\n",
    "#### - High : positive(), negative()\n",
    "#### - Moderate : positive(Item_MRP), negative()\n",
    "#### - Low : positive(), negative(Item_Visibility)\n",
    "#### - Very Low : positive(Item_Weight, Outlet_Age), negative()\n",
    "\n",
    "\n",
    "### . Categorical-Numerical ('Item_Outlet_Sales' vs others)\n",
    "#### - Outliers for different labels of Categorical Features.\n",
    "#### - Foods Item are contributing more for sales than Drinks and Non Consumables.\n",
    "#### - Regular Fat items are giving more sales than Low Fat and Non Edible. But more units are sold for Low Fat items.\n",
    "#### - Maximum units sold for 'Fruits and Vegetables','Snack Foods', and 'Household'. Highest sale is 'Seafood','Starchy Foods', and 'Dairy Foods'.\n",
    "#### - Outlets with ID OUT027 has highest sale and ID OUT010, and OUT019 have lowest sales.\n",
    "#### - Medium size outlets have more sales, but more items are sold in Small size outlets.\n",
    "#### - Highest sale is in Tier 2 location outlets, but more units are sold in Tier 3 location types.\n",
    "#### - Supermarket Type 3 are giving more sales, but more items are sold in Supermarket Type 1.\n",
    "#### - Oldest (28 Yrs) outlet has given more sales in comparison to others, but outlet aged 15 Yrs is lowest in terms of sales. \n",
    "\n",
    "\n",
    "### . Categorical-Categorical ('Item_Outlet_Sales' as Value across categorical features)\n",
    "#### - Foods and Drinks with Regular and Low Fat respectively are giving more sales.\n",
    "#### - Foods, Drinks, Non Consumables with Seafood, Hard Drinks, and Households are contributing more for sales.\n",
    "#### - Items in each category have highest sales in Medium size, Tier 2, Supermarket Type 3 outlets.\n",
    "\n",
    "#### - Regular Fat items are contributing more for sales, except for few Low Fat Items.\n",
    "#### - Regular Fat have higher sales in Medium size, Tier 2 and Tier 1 type, and Supermarket Type 3 outlets.\n",
    "#### - Non Edible items are giving more sales in Medium size, Tier 2 type, and Supermarket Type 3 outlets.\n",
    "\n",
    "#### - Higher sales for Medium size, Tier 3, and Supermarket Type 3 outlets.\n",
    "#### - Higher sales for Small size, Tier 2 outlets.\n",
    "#### - Supermarket Type 1 has higher sales for Medium than High \n",
    "\n",
    "#### - Sale of Grocery Store is lower in all location types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d429c-bf00-4db5-84e3-29275442c327",
   "metadata": {},
   "source": [
    "# D. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc2a38-f7ce-4d4b-b7dd-812d683752ec",
   "metadata": {},
   "source": [
    "## a. Observations\n",
    "\n",
    "#### 1. Drop non relevant features from the dataset.\n",
    "#### 2. Outliers handling using IQR method and Capping.\n",
    "#### 3. Feature transformation checks.\n",
    "#### 4. Scaling for numerical float type features.\n",
    "#### 5. Categorical data encoding using Ordinal Encoding and One Hot Encoding Techniques.\n",
    "#### 6. Feature hasher for high cardinality categorical features to reduce dimensions.   (Not Used)\n",
    "#### 7. Feature selection to increase the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4f216-c2ec-468d-89df-0b660a145468",
   "metadata": {},
   "source": [
    "## b. Steps of Feature Engineering\n",
    "#### 1. Drop non relevant features from the observations.\n",
    "\n",
    "#### 2. Oultier Detection and Handling using Capping Technique\n",
    "\n",
    "##### - Detect and handle outliers in numerical features of Train dataset only.\n",
    "#### 3. Feature Transformation (to be applied in pipeline)\n",
    "\n",
    "#### Checking various features transformations: (Log), (Square), (Reciprocal), (Square Root), (Exponential), (Yeo-Johnson)\n",
    "##### - 'Yeo-Johnson' Transformation is performing better in comparison to other transformations.\n",
    "##### - Apply 'Yeo-Johnson' on numerical features of Train, Validation, and Test dataset.\n",
    "#### 4. Scaling (StandardScaler / MinMaxScaler) (to be applied in pipeline)\n",
    "\n",
    "##### - Apply 'StandardScaler' on numerical features of Train, Validation, and Test dataset to reduce the skew.\n",
    "#### 5. Categorical features encoding using Ordinal encoding and OneHot encoding techniques\n",
    "\n",
    "#### 6. Feature hasher (Not Used)\n",
    "\n",
    "#### 7. Feature Selection Techniques (to be applied in pipeline)\n",
    "##### - Apply SelectKBest with mutual_info_regression to select the top k features for Model Building using estimators.\n",
    "##### - Treat Train, Validation, and Test dataset with feature selection strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b51b7b-4eb3-47ab-88c6-ad22ed4777f9",
   "metadata": {},
   "source": [
    "## c. Saving the feature engineered train and test datasets into CSV and PKL files\n",
    "#### - Train dataset is saved after outlier detection and handling step.\n",
    "##### - 'bms_FE_train_final.csv'\n",
    "##### - 'bms_FE_train_final.pkl'\n",
    "\n",
    "#### - Validation and Test data.\n",
    "##### - 'bms_FE_valid_final.csv'\n",
    "##### - 'bms_FE_valid_final.pkl'\n",
    "##### - 'bms_FE_test_final.csv'\n",
    "##### - 'bms_FE_test_final.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6eeaf-22ef-434b-af2d-b75e2ae2e3a5",
   "metadata": {},
   "source": [
    "# E. ML MODELS IMPLEMENTATIONS & RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a270cb8-356b-4cf5-af04-caf35ce80a86",
   "metadata": {},
   "source": [
    "## A. Simple Model (using pipeline)\n",
    "\n",
    "#### 1. Feature Engineering. (Column Transformation, Standard Scaler, Ordinal Encoder, One Hot Encoder, SelectKBest {mutual info regression})\n",
    "#### 2. No Hyper Parameters tuning used.\n",
    "\n",
    "#### 3. Dataset Size:\n",
    "- Train Dataset size : (8323, 11)\n",
    "- Validation Dataset size : (100, 11)\n",
    "\n",
    "#### 4. Model: LinearRegression()\n",
    "- Train Dataset R2 score : 0.3536, RMSE : 1372.1487 \n",
    "\n",
    "- Validation Dataset R2 score : 0.2358, RMSE : 1303.4476\n",
    "\n",
    "- ***Acceptable performance for Train and Validation sets.***\n",
    "- ***Slight overfitting for Train dataset.***\n",
    "- ***Performing well on both datasets.***\n",
    "\n",
    "#### 5. Cross-Validation Score (n_splits=5, shuffle=True, random_state=46)\n",
    "- Mean R2 Score: 0.3466\n",
    "- Mean RMSE Score: 1378.9928"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b517b-a2ba-49ad-825d-3b246f2557e8",
   "metadata": {},
   "source": [
    "## B. Best Tuned Model (using pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ada83e-448a-4ef1-8342-fbcd79c94356",
   "metadata": {},
   "source": [
    "#### 1. Models Hyper Tuned using GridSearchCV: KFold(n_splits=5, shuffle=True, random_state=46)\n",
    "- 'Lin_Reg':LinearRegression(),\n",
    "    \n",
    "- 'Lasso':Lasso(alpha=0.5, max_iter=1000),\n",
    "    \n",
    "- 'Ridge':Ridge(alpha=0.05, max_iter=1500), \n",
    "\n",
    "- 'KN_REG':KNeighborsRegressor(algorithm='brute', metric='euclidean', n_neighbors=17, weights='uniform'),\n",
    "\n",
    "- 'SV_REG':SVR(C=1.0, degree=2, gamma='scale', kernel='linear'),\n",
    "\n",
    "- 'DT_REG':DecisionTreeRegressor(criterion='squared_error', max_depth=5, min_impurity_decrease=0.0, min_samples_split=0.3, splitter='best', random_state=46),\n",
    "\n",
    "- 'BAG_REG':BaggingRegressor(bootstrap=True, estimator=KNeighborsRegressor(), max_samples=0.25, n_estimators=200, oob_score=True, random_state=46),\n",
    "\n",
    "- 'RF_REG':RandomForestRegressor(bootstrap=True, criterion='squared_error', max_depth=5, max_samples=0.25, n_estimators=100, oob_score=True, random_state=46),\n",
    "\n",
    "- 'GB_REG':GradientBoostingRegressor(criterion='squared_error',learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.75, random_state=46),\n",
    "\n",
    "- 'HGB_REG':HistGradientBoostingRegressor(learning_rate=0.1, max_depth=3, max_iter=50, max_leaf_nodes=20, l2_regularization=0.1, random_state=46),\n",
    "\n",
    "- 'XGB_REG':XGBRegressor(objective='reg:squarederror', eval_metric='rmse', seed=46, eta=0.1, gamma=0.01, max_depth=3, n_estimators=50, subsample=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908d993-f1fb-4b1d-9c85-16630dcbcd22",
   "metadata": {},
   "source": [
    "#### 2. Model's Performance Comparison\n",
    "\n",
    "##### **Model**    ---> ***R2_Score***\n",
    "\n",
    "##### 1. **RF_REG**   --->  ***0.5885***\n",
    "##### 2. **HGB_REG**  --->  ***0.5877***\n",
    "##### 3. **XGB_REG**  --->  ***0.5876***\n",
    "##### 4. **GB_REG**   --->  ***0.5868***\n",
    "##### 5. **BAG_REG**  --->  ***0.5525***\n",
    "##### 6. **KN_REG**   --->  ***0.5455***\n",
    "##### 7. **DT_REG**   --->  ***0.5011***\n",
    "##### 8. **Ridge**    --->  ***0.3491***\n",
    "##### 9. **Lin_Reg**  --->  ***0.3466***\n",
    "##### 10. **SV_REG**  --->  ***0.3267***\n",
    "##### 11. **Lasso**   --->  ***-0.0132***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef998410-56f5-4da1-a664-87ac3a5871a2",
   "metadata": {},
   "source": [
    "#### 3. Best Model and Parameters\n",
    "\n",
    "- **RandomForestRegressor** ***(bootstrap=True, criterion='squared_error', max_depth=5, max_samples=0.25, n_estimators=100, oob_score=True, random_state=46)***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a349e-8b09-4208-a02f-ff9feba37d27",
   "metadata": {},
   "source": [
    "#### 4. Best Model Results\n",
    "\n",
    "- KFold(n_splits=5, shuffle=True, random_state=46)\n",
    "-- Mean R2 Score: 0.58849, Mean RMSE Score: 1094.27541,  dataset size : (8323, 11)\n",
    "\n",
    "- Validation Data : Mean R2 Score: 0.6415, Mean RMSE Score: 892.7377, dataset size : (100,11)\n",
    "- ***Test Data : Mean R2 Score: 0.5689, Mean RMSE Score: 1232.2241***, dataset size : (100,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91360b-d754-4407-aec6-0a714e6efa01",
   "metadata": {},
   "source": [
    "## C. Production Model\n",
    "\n",
    "- **RandomForestRegressor** ***(bootstrap=True, criterion='squared_error', max_depth=5, max_samples=0.25, n_estimators=100, oob_score=True, random_state=46)***\n",
    "- KFold(n_splits=10, shuffle=True, random_state=46), Mean R2 Score: 0.5884, Mean RMSE Score: 1092.5346, dataset size : (8423, 11)\n",
    "- ***Test Data : Mean R2 Score: 0.5693, Mean RMSE Score: 1231.6046***, dataset size : (100,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c6b07-46ea-4aae-9848-284450659728",
   "metadata": {},
   "source": [
    "## D. Gradio App Deployment Files\n",
    "\n",
    "- App development is done using 'Production Model' and 'Production Data'.\n",
    "- Production Model saved as 'bms_mdl_prod.pkl' file.\n",
    "- Xtrain set is saved 'bms_X_prod.pkl' file. To access the feature unique values, and ranges.\n",
    "- Test set is saved 'bms_FE_test_final.pkl' file. To test the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c0e5f-4f62-4238-908a-54166975897c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
